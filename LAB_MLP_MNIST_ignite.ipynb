{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Modules & Libraries**\n",
        "* ignite is a high-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently. It supports Weights & Biases handler to log metrics, model/optimizer parameters, gradients during training and validation. "
      ],
      "metadata": {
        "id": "7ROEe5q04KUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-ignite"
      ],
      "metadata": {
        "id": "cv6VXqh2-lib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3231288-87a2-4223-d6b4-7d5a3ebf83b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.10-py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-ignite) (3.0.9)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "A4yofAW33ee5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, Normalize, ToTensor\n",
        "from ignite.handlers import EarlyStopping \n",
        "from ignite.engine import Engine, Events # Runs a given process_function over each batch of a dataset, emitting events as it goes.\n",
        "from ignite.utils import setup_logger # Ignite makes use of handlers to configure what we want to log / suivre le logging\n",
        "from ignite.contrib.handlers import TensorboardLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Definition**"
      ],
      "metadata": {
        "id": "OQ6vub1X4CHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, N1, N2, output_dim):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim,N1)\n",
        "    self.fc2 = nn.Linear(N1, N2)\n",
        "    self.fc3 = nn.Linear(N2, output_dim)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.relu = nn.ReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out=self.dropout(self.relu(self.fc1(x)))\n",
        "    out=self.dropout(self.relu(self.fc2(out)))\n",
        "    out=self.fc3(out)        \n",
        "    return out"
      ],
      "metadata": {
        "id": "tU9ojrlG3mCp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preparation**"
      ],
      "metadata": {
        "id": "4S0v1z-x4r6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(batch_size):\n",
        "  # transform to normalize the data\n",
        "  transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
        "  \n",
        "  # Download and load the training and test datasets\n",
        "  trainset = MNIST(root='MNIST', download=True, train=True, transform=transform)\n",
        "  testset = MNIST(root='MNIST', download=True, train=False, transform=transform)\n",
        "\n",
        "  trainset_size = round(len(trainset) * 0.8)\n",
        "  validset_size = len(trainset) - trainset_size\n",
        "  trainset, validset = random_split(trainset, [trainset_size, validset_size])\n",
        "\n",
        "  train_dl = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "  valid_dl = DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
        "  test_dl = DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_dl, valid_dl, test_dl"
      ],
      "metadata": {
        "id": "ah7Zc__x4zF9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Setting**"
      ],
      "metadata": {
        "id": "viO-tTsrEf3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MLP(784, 128, 64, 10)\n",
        "model.to(device)  # Move model before creating optimizer\n",
        "print(model)\n",
        "optimizer = Adam(model.parameters(), lr=0.002)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4RNGfdoEgRE",
        "outputId": "7cec28d7-14f8-4fb8-f74d-3afbe69e8f02"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "ST1UzLPP5YKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(engine, batch):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  x, y = batch[0].to(device), batch[1].to(device)\n",
        "  y_pred = model(x.view(x.shape[0], -1))\n",
        "  loss = criterion(y_pred, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item()\n",
        "\n",
        "def validation_step(engine, batch):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    inputs = batch[0].to(device)\n",
        "    labels = batch[1].to(device)\n",
        "    outputs = model(inputs.view(inputs.shape[0], -1))\n",
        "    _,predicted = torch.max(outputs.data, 1)      \n",
        "    accuracy = (predicted == labels).sum().item()/labels.size(0)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "2kNw26rrCacm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(model, device, optimizer, criterion, epochs, train_dl, valid_dl):\n",
        "\n",
        "  # Trainer\n",
        "  trainer = Engine(train_step)\n",
        "  trainer.logger = setup_logger(\"trainer\")\n",
        "\n",
        "  # Evaluator\n",
        "  Evaluator = Engine(validation_step)\n",
        "  Evaluator.logger = setup_logger(\"Evaluator\")\n",
        "  from ignite.engine import create_supervised_evaluator\n",
        "# Accuracy and loss metrics are defined\n",
        "  val_metrics = {\n",
        "  \"accuracy\": Accuracy(),\n",
        "  \"loss\": Loss(criterion)\n",
        "}\n",
        "  \n",
        "  def score_function(engine):\n",
        "    return Evaluator.state.output\n",
        "\n",
        "  # Early stopping handler\n",
        "  handler = EarlyStopping(patience=2, score_function=score_function, trainer=trainer)\n",
        "  Evaluator.add_event_handler(Events.COMPLETED, handler)\n",
        "  # Define a Tensorboard logger\n",
        "  tb_logger = TensorboardLogger(log_dir=\"quick-start-mnist-output\")\n",
        "\n",
        "# Attach handler to plot trainer's loss every 100 iterations\n",
        "  tb_logger.attach_output_handler(\n",
        "    trainer,\n",
        "    event_name=Events.ITERATION_COMPLETED(every=100),\n",
        "    tag=\"training\",\n",
        "    output_transform=lambda loss: {\"batchloss\": loss},\n",
        ")\n",
        "\n",
        "\n",
        "  \n",
        "  @trainer.on(Events.ITERATION_COMPLETED(every=100))\n",
        "  def log_training_loss(engine):\n",
        "    print(f\"ITERATION - Loss: {engine.state.output:.2f}\")\n",
        "        \n",
        "  @trainer.on(Events.EPOCH_COMPLETED)\n",
        "  def log_training_results(engine):\n",
        "    Evaluator.run(train_dl)\n",
        "    print(f\"Training Results - Epoch: {trainer.state.epoch} Accuracy: {Evaluator.state.output:.2f}\")\n",
        "\n",
        "  @trainer.on(Events.EPOCH_COMPLETED)\n",
        "  def log_validation_results(engine):\n",
        "    Evaluator.run(valid_dl)\n",
        "    print(f\"Validation Results - Epoch: {trainer.state.epoch} Accuracy: {Evaluator.state.output:.2f}\")\n",
        "\n",
        "  @trainer.on(Events.EPOCH_COMPLETED | Events.COMPLETED)\n",
        "  def log_time(engine):\n",
        "    print(f\"{trainer.last_event_name.name} took { trainer.state.times[trainer.last_event_name.name]} seconds\")\n",
        "\n",
        "  trainer.run(train_dl, max_epochs=epochs)\n",
        "  tb_logger.close()"
      ],
      "metadata": {
        "id": "SZYvFipKE4cf"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  # Data Preparation\n",
        "  train_dl, valid_dl, test_dl = prepare_data(batch_size=64)\n",
        "\n",
        "  run(model, device, optimizer, criterion, 10, train_dl, valid_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_GPi5FD5en1",
        "outputId": "7331c0f4-d53b-4687-8a8e-e925b8f23e11"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 11:14:09,927 trainer INFO: Engine run starting with max_epochs=10.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ITERATION - Loss: 0.14\n",
            "ITERATION - Loss: 0.33\n",
            "ITERATION - Loss: 0.14\n",
            "ITERATION - Loss: 0.31\n",
            "ITERATION - Loss: 0.32\n",
            "ITERATION - Loss: 0.19\n",
            "ITERATION - Loss: 0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 11:14:18,709 Evaluator INFO: Engine run starting with max_epochs=1.\n",
            "2022-11-22 11:14:26,517 Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:07.806\n",
            "2022-11-22 11:14:26,518 Evaluator INFO: Engine run complete. Time taken: 00:00:07.808\n",
            "2022-11-22 11:14:26,524 Evaluator INFO: Engine run starting with max_epochs=1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 1 Accuracy: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 11:14:28,455 Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:01.929\n",
            "2022-11-22 11:14:28,456 Evaluator INFO: Engine run complete. Time taken: 00:00:01.931\n",
            "2022-11-22 11:14:28,461 trainer INFO: Epoch[1] Complete. Time taken: 00:00:18.531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results - Epoch: 1 Accuracy: 1.00\n",
            "EPOCH_COMPLETED took 8.779468536376953 seconds\n",
            "ITERATION - Loss: 0.22\n",
            "ITERATION - Loss: 0.08\n",
            "ITERATION - Loss: 0.25\n",
            "ITERATION - Loss: 0.19\n",
            "ITERATION - Loss: 0.22\n",
            "ITERATION - Loss: 0.18\n",
            "ITERATION - Loss: 0.37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 11:14:37,608 Evaluator INFO: Engine run starting with max_epochs=1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ITERATION - Loss: 0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 11:14:45,851 Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:08.236\n",
            "2022-11-22 11:14:45,853 Evaluator INFO: Engine run complete. Time taken: 00:00:08.238\n",
            "2022-11-22 11:14:45,858 Evaluator INFO: Engine run starting with max_epochs=1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Results - Epoch: 2 Accuracy: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-22 11:14:47,749 Evaluator INFO: Epoch[1] Complete. Time taken: 00:00:01.888\n",
            "2022-11-22 11:14:47,751 ignite.handlers.early_stopping.EarlyStopping INFO: EarlyStopping: Stop training\n",
            "2022-11-22 11:14:47,758 trainer INFO: Terminate signaled. Engine will stop after current iteration is finished.\n",
            "2022-11-22 11:14:47,760 Evaluator INFO: Engine run complete. Time taken: 00:00:01.899\n",
            "2022-11-22 11:14:47,762 trainer INFO: Engine run complete. Time taken: 00:00:37.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Results - Epoch: 2 Accuracy: 0.97\n",
            "EPOCH_COMPLETED took 9.144144058227539 seconds\n",
            "COMPLETED took 37.833301067352295 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TensorBoardLogger** handler allows to log metric results, model’s and optimizer’s parameters, gradients, and more during the training and validation for TensorBoard."
      ],
      "metadata": {
        "id": "ACBb72_v88oA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir=."
      ],
      "metadata": {
        "id": "qBoI-I99ZWim",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "88aeb9f1-bd28-44d8-8b57-e32cd55dc7b3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3p9md40FDFYU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}